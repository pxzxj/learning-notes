<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.15">
<title>d2l(chapter1-3)</title>
<link rel="stylesheet" href="css/site.css">
<link href="css/custom.css" rel="stylesheet">
<script src="js/setup.js"></script><script defer src="js/site.js"></script>

</head>
<body class="article toc2 toc-left"><div id="banner-container" class="container" role="banner">
  <div id="banner" class="contained" role="banner">
    <div id="switch-theme">
      <input type="checkbox" id="switch-theme-checkbox" />
      <label for="switch-theme-checkbox">Dark Theme</label>
    </div>
  </div>
</div>
<div id="tocbar-container" class="container" role="navigation">
  <div id="tocbar" class="contained" role="navigation">
    <button id="toggle-toc"></button>
  </div>
</div>
<div id="main-container" class="container">
  <div id="main" class="contained">
    <div id="doc" class="doc">
<div id="header">
<h1>d2l(chapter1-3)</h1>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<span id="back-to-index"><a href="index.html">Back to index</a></span><ul class="sectlevel1">
<li><a href="#_é¢„å¤‡çŸ¥è¯†">1. é¢„å¤‡çŸ¥è¯†</a>
<ul class="sectlevel2">
<li><a href="#_æ•°æ®æ“ä½œ">1.1. æ•°æ®æ“ä½œ</a></li>
<li><a href="#_æ•°æ®é¢„å¤„ç†">1.2. æ•°æ®é¢„å¤„ç†</a></li>
<li><a href="#_çº¿æ€§ä»£æ•°">1.3. çº¿æ€§ä»£æ•°</a></li>
<li><a href="#_å¾®ç§¯åˆ†">1.4. å¾®ç§¯åˆ†</a></li>
<li><a href="#_è‡ªåŠ¨å¾®åˆ†">1.5. è‡ªåŠ¨å¾®åˆ†</a></li>
</ul>
</li>
<li><a href="#_çº¿æ€§ç¥ç»ç½‘ç»œ">2. çº¿æ€§ç¥ç»ç½‘ç»œ</a>
<ul class="sectlevel2">
<li><a href="#_çº¿æ€§å›å½’">2.1. çº¿æ€§å›å½’</a></li>
<li><a href="#_çº¿æ€§å›å½’çš„ä»é›¶å¼€å§‹å®ç°">2.2. çº¿æ€§å›å½’çš„ä»é›¶å¼€å§‹å®ç°</a></li>
<li><a href="#_çº¿æ€§å›å½’çš„ç®€æ´å®ç°">2.3. çº¿æ€§å›å½’çš„ç®€æ´å®ç°</a></li>
<li><a href="#_å›¾åƒåˆ†ç±»æ•°æ®é›†">2.4. å›¾åƒåˆ†ç±»æ•°æ®é›†</a></li>
<li><a href="#_softmaxå›å½’çš„ä»é›¶å¼€å§‹å®ç°">2.5. softmaxå›å½’çš„ä»é›¶å¼€å§‹å®ç°</a></li>
<li><a href="#_softmaxå›å½’çš„ç®€æ´å®ç°">2.6. softmaxå›å½’çš„ç®€æ´å®ç°</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_é¢„å¤‡çŸ¥è¯†"><a class="anchor" href="#_é¢„å¤‡çŸ¥è¯†"></a>1. é¢„å¤‡çŸ¥è¯†</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_æ•°æ®æ“ä½œ"><a class="anchor" href="#_æ•°æ®æ“ä½œ"></a>1.1. æ•°æ®æ“ä½œ</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># æŸ¥çœ‹pytorchä¸­çš„æ‰€æœ‰å‡½æ•°åæˆ–å±æ€§å
import torch

print(dir(torch.distributions))

print('1.å¼ é‡çš„åˆ›å»º')
# ones å‡½æ•°åˆ›å»ºä¸€ä¸ªå…·æœ‰æŒ‡å®šå½¢çŠ¶çš„æ–°å¼ é‡ï¼Œå¹¶å°†æ‰€æœ‰å…ƒç´ å€¼è®¾ç½®ä¸º 1
t = torch.ones(4)
print('t:', t)

x = torch.arange(12)
print('x:', x)
print('x shape:', x.shape)  # è®¿é—®å‘é‡çš„å½¢çŠ¶

y = x.reshape(3, 4)  # æ”¹å˜ä¸€ä¸ªå¼ é‡çš„å½¢çŠ¶è€Œä¸æ”¹å˜å…ƒç´ æ•°é‡å’Œå…ƒç´ å€¼
print('y:', y)
print('y.numel():', y.numel())  # è¿”å›å¼ é‡ä¸­å…ƒç´ çš„æ€»ä¸ªæ•°

z = torch.zeros(2, 3, 4)  # åˆ›å»ºä¸€ä¸ªå¼ é‡ï¼Œå…¶ä¸­æ‰€æœ‰å…ƒç´ éƒ½è®¾ç½®ä¸º0
print('z:', z)

w = torch.randn(2, 3, 4)  # æ¯ä¸ªå…ƒç´ éƒ½ä»å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º1çš„æ ‡å‡†é«˜æ–¯ï¼ˆæ­£æ€ï¼‰åˆ†å¸ƒä¸­éšæœºé‡‡æ ·ã€‚
print('w:', w)

q = torch.tensor([[1, 2, 3], [4, 3, 2], [7, 4, 3]])  # é€šè¿‡æä¾›åŒ…å«æ•°å€¼çš„ Python åˆ—è¡¨ï¼ˆæˆ–åµŒå¥—åˆ—è¡¨ï¼‰æ¥ä¸ºæ‰€éœ€å¼ é‡ä¸­çš„æ¯ä¸ªå…ƒç´ èµ‹äºˆç¡®å®šå€¼
print('q:', q)

print('2.å¼ é‡çš„è¿ç®—')
x = torch.tensor([1.0, 2, 4, 8])
y = torch.tensor([2, 2, 2, 2])
print(x + y)
print(x - y)
print(x * y)
print(x / y)
print(x ** y)  # **è¿ç®—ç¬¦æ˜¯æ±‚å¹‚è¿ç®—
print(torch.exp(x))

X = torch.arange(12, dtype=torch.float32).reshape(3, 4)
Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
print('catæ“ä½œ dim=0', torch.cat((X, Y), dim=0))
print('catæ“ä½œ dim=1', torch.cat((X, Y), dim=1))  # è¿ç»“ï¼ˆconcatenateï¼‰ ,å°†å®ƒä»¬ç«¯åˆ°ç«¯å †å ä»¥å½¢æˆæ›´å¤§çš„å¼ é‡ã€‚

print('X == Y', X == Y)  # é€šè¿‡ é€»è¾‘è¿ç®—ç¬¦ æ„å»ºäºŒå…ƒå¼ é‡
print('X &lt; Y', X &lt; Y)
print('å¼ é‡æ‰€æœ‰å…ƒç´ çš„å’Œ:', X.sum())  # å¼ é‡æ‰€æœ‰å…ƒç´ çš„å’Œ

print('3.å¹¿æ’­æœºåˆ¶')
a = torch.arange(3).reshape(3, 1)
b = torch.arange(2).reshape(1, 2)
print('a:', a)
print('b:', b)
print('a + b:', a + b)  # ç¥å¥‡çš„å¹¿æ’­è¿ç®—

print('4.ç´¢å¼•å’Œåˆ‡ç‰‡')
X = torch.arange(12, dtype=torch.float32).reshape(3, 4)
print('X:', X)
print('X[-1]:', X[-1])  # ç”¨ [-1] é€‰æ‹©æœ€åä¸€ä¸ªå…ƒç´ 
print('X[1:3]:', X[1:3])  # ç”¨ [1:3] é€‰æ‹©ç¬¬äºŒä¸ªå’Œç¬¬ä¸‰ä¸ªå…ƒç´ ]

X[1, 2] = 9  # å†™å…¥å…ƒç´ ã€‚
print('X:', X)

X[0:2, :] = 12  # å†™å…¥å…ƒç´ ã€‚
print('X:', X)

print('5.èŠ‚çº¦å†…å­˜')
before = id(Y)  # id()å‡½æ•°æä¾›äº†å†…å­˜ä¸­å¼•ç”¨å¯¹è±¡çš„ç¡®åˆ‡åœ°å€
Y = Y + X
print(id(Y) == before)

before = id(X)
X += Y
print(id(X) == before)  # ä½¿ç”¨ X[:] = X + Y æˆ– X += Y æ¥å‡å°‘æ“ä½œçš„å†…å­˜å¼€é”€ã€‚

before = id(X)
X[:] = X + Y
print(id(X) == before)  # ä½¿ç”¨ X[:] = X + Y æˆ– X += Y æ¥å‡å°‘æ“ä½œçš„å†…å­˜å¼€é”€ã€‚

print('6.è½¬æ¢ä¸ºå…¶ä»– Pythonå¯¹è±¡')
Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
A = Y.numpy()
print(type(A))  # æ‰“å°Açš„ç±»å‹
print(A)
B = torch.tensor(A)
print(type(B))  # æ‰“å°Bçš„ç±»å‹
print(B)

a = torch.tensor([3.5])
print(a, a.item(), float(a), int(a))</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_æ•°æ®é¢„å¤„ç†"><a class="anchor" href="#_æ•°æ®é¢„å¤„ç†"></a>1.2. æ•°æ®é¢„å¤„ç†</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import os

import numpy as np
import pandas as pd
import torch
from numpy import nan as NaN

os.makedirs(os.path.join('..', 'data'), exist_ok=True)  # åœ¨ä¸Šçº§ç›®å½•åˆ›å»ºdataæ–‡ä»¶å¤¹
datafile = os.path.join('..', 'data', 'house_tiny.csv')  # åˆ›å»ºæ–‡ä»¶
with open(datafile, 'w') as f:  # å¾€æ–‡ä»¶ä¸­å†™æ•°æ®
    f.write('NumRooms,Alley,Price\n')  # åˆ—å
    f.write('NA,Pave,127500\n')  # ç¬¬1è¡Œçš„å€¼
    f.write('2,NA,106000\n')  # ç¬¬2è¡Œçš„å€¼
    f.write('4,NA,178100\n')  # ç¬¬3è¡Œçš„å€¼
    f.write('NA,NA,140000\n')  # ç¬¬4è¡Œçš„å€¼

data = pd.read_csv(datafile)  # å¯ä»¥çœ‹åˆ°åŸå§‹è¡¨æ ¼ä¸­çš„ç©ºå€¼NAè¢«è¯†åˆ«æˆäº†NaN
print('1.åŸå§‹æ•°æ®:\n', data)

inputs, outputs = data.iloc[:, 0: 2], data.iloc[:, 2]
inputs = inputs.fillna(inputs.mean())  # ç”¨å‡å€¼å¡«å……NaN
print(inputs)
print(outputs)
# åˆ©ç”¨pandasä¸­çš„get_dummieså‡½æ•°æ¥å¤„ç†ç¦»æ•£å€¼æˆ–è€…ç±»åˆ«å€¼ã€‚
# [å¯¹äº inputs ä¸­çš„ç±»åˆ«å€¼æˆ–ç¦»æ•£å€¼ï¼Œæˆ‘ä»¬å°† â€œNaNâ€ è§†ä¸ºä¸€ä¸ªç±»åˆ«ã€‚] ç”±äº â€œAlleyâ€åˆ—åªæ¥å—ä¸¤ç§ç±»å‹çš„ç±»åˆ«å€¼ â€œPaveâ€ å’Œ â€œNaNâ€
inputs = pd.get_dummies(inputs, dummy_na=True)
print('2.åˆ©ç”¨pandasä¸­çš„get_dummieså‡½æ•°å¤„ç†:\n', inputs)

x, y = torch.tensor(inputs.values), torch.tensor(outputs.values)
print('3.è½¬æ¢ä¸ºå¼ é‡ï¼š')
print(x)
print(y)

# æ‰©å±•å¡«å……å‡½æ•°fillnaçš„ç”¨æ³•
df1 = pd.DataFrame([[1, 2, 3], [NaN, NaN, 2], [NaN, NaN, NaN], [8, 8, NaN]])  # åˆ›å»ºåˆå§‹æ•°æ®
print('4.å‡½æ•°fillnaçš„ç”¨æ³•ï¼š')
print(df1)
print(df1.fillna(100))  # ç”¨å¸¸æ•°å¡«å…… ï¼Œé»˜è®¤ä¸ä¼šä¿®æ”¹åŸå¯¹è±¡
print(df1.fillna({0: 10, 1: 20, 2: 30}))  # é€šè¿‡å­—å…¸å¡«å……ä¸åŒçš„å¸¸æ•°ï¼Œé»˜è®¤ä¸ä¼šä¿®æ”¹åŸå¯¹è±¡
print(df1.fillna(method='ffill'))  # ç”¨å‰é¢çš„å€¼æ¥å¡«å……
# print(df1.fillna(0, inplace=True))  # inplace= Trueç›´æ¥ä¿®æ”¹åŸå¯¹è±¡

df2 = pd.DataFrame(np.random.randint(0, 10, (5, 5)))  # éšæœºåˆ›å»ºä¸€ä¸ª5*5
df2.iloc[1:4, 3] = NaN
df2.iloc[2:4, 4] = NaN  # æŒ‡å®šçš„ç´¢å¼•å¤„æ’å…¥å€¼
print(df2)
print(df2.fillna(method='bfill', limit=2))  # é™åˆ¶å¡«å……ä¸ªæ•°
print(df2.fillna(method="ffill", limit=1, axis=1))  #</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_çº¿æ€§ä»£æ•°"><a class="anchor" href="#_çº¿æ€§ä»£æ•°"></a>1.3. çº¿æ€§ä»£æ•°</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch

print('1.æ ‡é‡ä¸å˜é‡')
x = torch.tensor([3.0])
y = torch.tensor([2.0])
print(x + y, x * y, x / y, x ** y)

x = torch.arange(4)
print('2.å‘é‡')
print('x:', x)
print('x[3]:', x[3])  # é€šè¿‡å¼ é‡çš„ç´¢å¼•æ¥è®¿é—®ä»»ä¸€å…ƒç´ 
print('å¼ é‡çš„å½¢çŠ¶:', x.shape)  # å¼ é‡çš„å½¢çŠ¶
print('å¼ é‡çš„é•¿åº¦:', len(x))  # å¼ é‡çš„é•¿åº¦
z = torch.arange(24).reshape(2, 3, 4)
print('ä¸‰ç»´å¼ é‡çš„é•¿åº¦:', len(z))

print('3.çŸ©é˜µ')
A = torch.arange(20).reshape(5, 4)
print('A:', A)
print('A.shape:', A.shape)
print('A.shape[-1]:', A.shape[-1])
print('A.T:', A.T)  # çŸ©é˜µçš„è½¬ç½®

print('4.çŸ©é˜µçš„è®¡ç®—')
A = torch.arange(20, dtype=torch.float32).reshape(5, 4)
B = A.clone()  # é€šè¿‡åˆ†é…æ–°å†…å­˜ï¼Œå°†Açš„ä¸€ä¸ªå‰¯æœ¬åˆ†é…ç»™B
print('A:', A)
print('B:', B)
print('A + B:', A + B)  # çŸ©é˜µç›¸åŠ 
print('A * B:', A * B)  # çŸ©é˜µç›¸ä¹˜

a = 2
X = torch.arange(24).reshape(2, 3, 4)
print('X:', X)
print('a + X:', a + X)  # çŸ©é˜µçš„å€¼åŠ ä¸Šæ ‡é‡
print('a * X:', a * X)
print((a * X).shape)

print('5.çŸ©é˜µçš„sumè¿ç®—')
print('A:', A)
print('A.shape:', A.shape)
print('A.sum():', A.sum())
print('A.sum(axis=0):', A.sum(axis=0))  # æ²¿0è½´æ±‡æ€»ä»¥ç”Ÿæˆè¾“å‡ºå‘é‡
print('A.sum(axis=1):', A.sum(axis=1))  # æ²¿1è½´æ±‡æ€»ä»¥ç”Ÿæˆè¾“å‡ºå‘é‡
print('A.sum(axis=1, keepdims=True)', A.sum(axis=1, keepdims=True))  # è®¡ç®—æ€»å’Œä¿æŒè½´æ•°ä¸å˜
print('A.sum(axis=[0, 1]):', A.sum(axis=[0, 1]))  # Same as `A.sum()`
print('A.mean():', A.mean())
print('A.sum() / A.numel():', A.sum() / A.numel())

print('6.å‘é‡-å‘é‡ç›¸ä¹˜ï¼ˆç‚¹ç§¯ï¼‰')
x = torch.arange(4, dtype=torch.float32)
y = torch.ones(4, dtype=torch.float32)
print('x:', x)
print('y:', y)
print('å‘é‡-å‘é‡ç‚¹ç§¯:', torch.dot(x, y))

print('7.çŸ©é˜µ-å‘é‡ç›¸ä¹˜(å‘é‡ç§¯)')
print('A:', A)  # 5*4ç»´
print('x:', x)  # 4*1ç»´
print('torch.mv(A, x):', torch.mv(A, x))

print('8.çŸ©é˜µ-çŸ©é˜µç›¸ä¹˜(å‘é‡ç§¯)')
print('A:', A)  # 5*4ç»´
B = torch.ones(4, 3)  # 4*3ç»´
print('B:', B)
print('torch.mm(A, B):', torch.mm(A, B))

print('9.èŒƒæ•°')
u = torch.tensor([3.0, -4.0])
print('å‘é‡çš„ğ¿2èŒƒæ•°:', torch.norm(u))  # å‘é‡çš„ğ¿2èŒƒæ•°
print('å‘é‡çš„ğ¿1èŒƒæ•°:', torch.abs(u).sum())  # å‘é‡çš„ğ¿1èŒƒæ•°
v = torch.ones((4, 9))
print('v:', v)
print('çŸ©é˜µçš„ğ¿2èŒƒæ•°:', torch.norm(v))  # çŸ©é˜µçš„ğ¿2èŒƒæ•°

print('10.æ ¹æ®ç´¢å¼•è®¿é—®çŸ©é˜µ')
y = torch.arange(10).reshape(5, 2)
print('y:', y)
index = torch.tensor([1, 4])
print('y[index]:', y[index])

print('11.ç†è§£pytorchä¸­çš„gather()å‡½æ•°')
a = torch.arange(15).view(3, 5)
print('11.1äºŒç»´çŸ©é˜µä¸Šgather()å‡½æ•°')
print('a:', a)
b = torch.zeros_like(a)
b[1][2] = 1  ##ç»™æŒ‡å®šç´¢å¼•çš„å…ƒç´ èµ‹å€¼
b[0][0] = 1  ##ç»™æŒ‡å®šç´¢å¼•çš„å…ƒç´ èµ‹å€¼
print('b:', b)
c = a.gather(0, b)  # dim=0
d = a.gather(1, b)  # dim=1
print('d:', d)
print('11.2ä¸‰ç»´çŸ©é˜µä¸Šgather()å‡½æ•°')
a = torch.randint(0, 30, (2, 3, 5))
print('a:', a)
index = torch.LongTensor([[[0, 1, 2, 0, 2],
                           [0, 0, 0, 0, 0],
                           [1, 1, 1, 1, 1]],
                          [[1, 2, 2, 2, 2],
                           [0, 0, 0, 0, 0],
                           [2, 2, 2, 2, 2]]])
print(a.size() == index.size())
b = torch.gather(a, 1, index)
print('b:', b)
c = torch.gather(a, 2, index)
print('c:', c)
index2 = torch.LongTensor([[[0, 1, 1, 0, 1],
                            [0, 1, 1, 1, 1],
                            [1, 1, 1, 1, 1]],
                           [[1, 0, 0, 0, 0],
                            [0, 0, 0, 0, 0],
                            [1, 1, 0, 0, 0]]])
d = torch.gather(a, 0, index2)
print('d:', d)

print('12.ç†è§£pytorchä¸­çš„max()å’Œargmax()å‡½æ•°')
a = torch.tensor([[1, 2, 3], [3, 2, 1]])
b = a.argmax(1)
c = a.max(1)
d = a.max(1)[1]
print('a:', a)
print('a.argmax(1):', b)
print('a.max(1):', c)
print('a.max(1)[1]:', d)

print('13.item()å‡½æ•°')
a = torch.Tensor([1, 2, 3])
print('a[0]:', a[0])  # ç›´æ¥å–ç´¢å¼•è¿”å›çš„æ˜¯tensoræ•°æ®
print('a[0].item():', a[0].item())  # è·å–python number</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_å¾®ç§¯åˆ†"><a class="anchor" href="#_å¾®ç§¯åˆ†"></a>1.4. å¾®ç§¯åˆ†</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import numpy as np
from d2l import torch as d2l
import os
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"


def f(x):
    return 3 * x ** 2 - 4 * x


def numerical_lim(f, x, h):
    return (f(x + h) - f(x)) / h


h = 0.1
for i in range(5):
    print(f'h={h:.5f}, numerical limit={numerical_lim(f, 1, h):.5f}')
    h *= 0.1

x = np.arange(0, 3, 0.1)
d2l.plot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])
d2l.plt.show();

x = np.arange(0.5, 3, 0.2)
d2l.plot(x, [x ** 3 - 1 / x, 4 * x - 4], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])
d2l.plt.show();</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_è‡ªåŠ¨å¾®åˆ†"><a class="anchor" href="#_è‡ªåŠ¨å¾®åˆ†"></a>1.5. è‡ªåŠ¨å¾®åˆ†</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch

print('1.è‡ªåŠ¨æ¢¯åº¦è®¡ç®—')
x = torch.arange(4.0, requires_grad=True)  # 1.å°†æ¢¯åº¦é™„åŠ åˆ°æƒ³è¦å¯¹å…¶è®¡ç®—åå¯¼æ•°çš„å˜é‡
print('x:', x)
print('x.grad:', x.grad)
y = 2 * torch.dot(x, x)  # 2.è®°å½•ç›®æ ‡å€¼çš„è®¡ç®—
print('y:', y)
y.backward()  # 3.æ‰§è¡Œå®ƒçš„åå‘ä¼ æ’­å‡½æ•°
print('x.grad:', x.grad)  # 4.è®¿é—®å¾—åˆ°çš„æ¢¯åº¦
print('x.grad == 4*x:', x.grad == 4 * x)

## è®¡ç®—å¦ä¸€ä¸ªå‡½æ•°
x.grad.zero_()
y = x.sum()
print('y:', y)
y.backward()
print('x.grad:', x.grad)

# éæ ‡é‡å˜é‡çš„åå‘ä¼ æ’­
x.grad.zero_()
print('x:', x)
y = x * x
y.sum().backward()
print('x.grad:', x.grad)


def f(a):
    b = a * 2
    print(b.norm())
    while b.norm() &lt; 1000:  # æ±‚L2èŒƒæ•°ï¼šå…ƒç´ å¹³æ–¹å’Œçš„å¹³æ–¹æ ¹
        b = b * 2
    if b.sum() &gt; 0:
        c = b
    else:
        c = 100 * b
    return c


print('2.Pythonæ§åˆ¶æµçš„æ¢¯åº¦è®¡ç®—')
a = torch.tensor(2.0)  # åˆå§‹åŒ–å˜é‡
a.requires_grad_(True)  # 1.å°†æ¢¯åº¦èµ‹ç»™æƒ³è¦å¯¹å…¶æ±‚åå¯¼æ•°çš„å˜é‡
print('a:', a)
d = f(a)  # 2.è®°å½•ç›®æ ‡å‡½æ•°
print('d:', d)
d.backward()  # 3.æ‰§è¡Œç›®æ ‡å‡½æ•°çš„åå‘ä¼ æ’­å‡½æ•°
print('a.grad:', a.grad)  # 4.è·å–æ¢¯åº¦</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_çº¿æ€§ç¥ç»ç½‘ç»œ"><a class="anchor" href="#_çº¿æ€§ç¥ç»ç½‘ç»œ"></a>2. çº¿æ€§ç¥ç»ç½‘ç»œ</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_çº¿æ€§å›å½’"><a class="anchor" href="#_çº¿æ€§å›å½’"></a>2.1. çº¿æ€§å›å½’</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import math
import os

import numpy as np
import torch
from d2l import torch as d2l

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

n = 10000
a = torch.ones(n)
b = torch.ones(n)
c = torch.zeros(n)
timer = d2l.Timer()
for i in range(n):
    c[i] = a[i] + b[i]
print(c)
print("{0:.5f} sec".format(timer.stop()))

timer.start()
d = a + b
print(d)
print("{0:.5f} sec".format(timer.stop()))


def normal(x, mu, sigma):
    p = 1 / math.sqrt(2 * math.pi * sigma ** 2)
    return p * np.exp((- 0.5 / sigma ** 2) * (x - mu) ** 2)


## å¯è§†åŒ–æ­£æ€åˆ†å¸ƒ
x = np.arange(-7, 7, 0.01)
params = [(0, 1), (0, 2), (3, 1)]
d2l.plot(x, [normal(x, mu, sigma) for mu, sigma in params], xlabel='x', ylabel='p(x)', figsize=(4.5, 2.5),
         legend=[f'mean {mu}, std {sigma}' for mu, sigma in params])
d2l.plt.show()</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_çº¿æ€§å›å½’çš„ä»é›¶å¼€å§‹å®ç°"><a class="anchor" href="#_çº¿æ€§å›å½’çš„ä»é›¶å¼€å§‹å®ç°"></a>2.2. çº¿æ€§å›å½’çš„ä»é›¶å¼€å§‹å®ç°</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import random

import torch

## with torch.no_grad() åˆ™ä¸»è¦æ˜¯ç”¨äºåœæ­¢autogradæ¨¡å—çš„å·¥ä½œï¼Œ
## ä»¥èµ·åˆ°åŠ é€Ÿå’ŒèŠ‚çœæ˜¾å­˜çš„ä½œç”¨ï¼Œå…·ä½“è¡Œä¸ºå°±æ˜¯åœæ­¢gradientè®¡ç®—ï¼Œä»è€ŒèŠ‚çœäº†GPUç®—åŠ›å’Œæ˜¾å­˜ï¼Œä½†æ˜¯å¹¶ä¸ä¼šå½±å“dropoutå’Œbatchnormå±‚çš„è¡Œä¸ºã€‚

## mmåªèƒ½è¿›è¡ŒçŸ©é˜µä¹˜æ³•,ä¹Ÿå°±æ˜¯è¾“å…¥çš„ä¸¤ä¸ªtensorç»´åº¦åªèƒ½æ˜¯( n Ã— m ) (n\times m)(nÃ—m)å’Œ( m Ã— p ) (m\times p)(mÃ—p)
## bmmæ˜¯ä¸¤ä¸ªä¸‰ç»´å¼ é‡ç›¸ä¹˜, ä¸¤ä¸ªè¾“å…¥tensorç»´åº¦æ˜¯( b Ã— n Ã— m )å’Œ( b Ã— m Ã— p ), ç¬¬ä¸€ç»´bä»£è¡¨batch sizeï¼Œè¾“å‡ºä¸º( b Ã— n Ã— p )
## matmulå¯ä»¥è¿›è¡Œå¼ é‡ä¹˜æ³•, è¾“å…¥å¯ä»¥æ˜¯é«˜ç»´.

## pythonçŸ¥è¯†è¡¥å……ï¼š
## Python3 range() å‡½æ•°è¿”å›çš„æ˜¯ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ï¼ˆç±»å‹æ˜¯å¯¹è±¡ï¼‰ï¼Œè€Œä¸æ˜¯åˆ—è¡¨ç±»å‹ï¼Œ æ‰€ä»¥æ‰“å°çš„æ—¶å€™ä¸ä¼šæ‰“å°åˆ—è¡¨ã€‚
## Python3 list() å‡½æ•°æ˜¯å¯¹è±¡è¿­ä»£å™¨ï¼Œå¯ä»¥æŠŠrange()è¿”å›çš„å¯è¿­ä»£å¯¹è±¡è½¬ä¸ºä¸€ä¸ªåˆ—è¡¨ï¼Œè¿”å›çš„å˜é‡ç±»å‹ä¸ºåˆ—è¡¨ã€‚
## Python3 range(start, stop[, step])
## Python3 shuffle() æ–¹æ³•å°†åºåˆ—çš„æ‰€æœ‰å…ƒç´ éšæœºæ’åºã€‚shuffle()æ˜¯ä¸èƒ½ç›´æ¥è®¿é—®çš„ï¼Œéœ€è¦å¯¼å…¥ random æ¨¡å—ã€‚ä¸¾ä¾‹ï¼šrandom.shuffle (list)
## Python3 yieldæ˜¯pythonä¸­çš„ç”Ÿæˆå™¨


## äººé€ æ•°æ®é›†
def create_data(w, b, nums_example):
    X = torch.normal(0, 1, (nums_example, len(w)))
    y = torch.matmul(X, w) + b
    print("y_shape:", y.shape)
    y += torch.normal(0, 0.01, y.shape)  # åŠ å…¥å™ªå£°
    return X, y.reshape(-1, 1)  # yä»è¡Œå‘é‡è½¬ä¸ºåˆ—å‘é‡


true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = create_data(true_w, true_b, 1000)


## è¯»æ•°æ®é›†
def read_data(batch_size, features, lables):
    nums_example = len(features)
    indices = list(range(nums_example))  # ç”Ÿæˆ0-999çš„å…ƒç»„ï¼Œç„¶åå°†range()è¿”å›çš„å¯è¿­ä»£å¯¹è±¡è½¬ä¸ºä¸€ä¸ªåˆ—è¡¨
    random.shuffle(indices)  # å°†åºåˆ—çš„æ‰€æœ‰å…ƒç´ éšæœºæ’åºã€‚
    for i in range(0, nums_example, batch_size):  # range(start, stop, step)
        index_tensor = torch.tensor(indices[i: min(i + batch_size, nums_example)])
        yield features[index_tensor], lables[index_tensor]  # é€šè¿‡ç´¢å¼•è®¿é—®å‘é‡


batch_size = 10
for X, y in read_data(batch_size, features, labels):
    print("X:", X, "\ny", y)
    break;

##åˆå§‹åŒ–å‚æ•°
w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)


# å®šä¹‰æ¨¡å‹
def net(X, w, b):
    return torch.matmul(X, w) + b


# å®šä¹‰æŸå¤±å‡½æ•°
def loss(y_hat, y):
    # print("y_hat_shape:",y_hat.shape,"\ny_shape:",y.shape)
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2  # è¿™é‡Œä¸ºä»€ä¹ˆè¦åŠ  y_hat_shape: torch.Size([10, 1])  y_shape: torch.Size([10])


# å®šä¹‰ä¼˜åŒ–ç®—æ³•
def sgd(params, batch_size, lr):
    with torch.no_grad():  # with torch.no_grad() åˆ™ä¸»è¦æ˜¯ç”¨äºåœæ­¢autogradæ¨¡å—çš„å·¥ä½œï¼Œ
        for param in params:
            param -= lr * param.grad / batch_size  ##  è¿™é‡Œç”¨param = param - lr * param.grad / batch_sizeä¼šå¯¼è‡´å¯¼æ•°ä¸¢å¤±ï¼Œ zero_()å‡½æ•°æŠ¥é”™
            param.grad.zero_()  ## å¯¼æ•°å¦‚æœä¸¢å¤±äº†ï¼Œä¼šæŠ¥é”™â€˜NoneTypeâ€™ object has no attribute â€˜zero_â€™


# è®­ç»ƒæ¨¡å‹
lr = 0.03
num_epochs = 3

for epoch in range(0, num_epochs):
    for X, y in read_data(batch_size, features, labels):
        f = loss(net(X, w, b), y)
        # å› ä¸º`f`å½¢çŠ¶æ˜¯(`batch_size`, 1)ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚`f`ä¸­çš„æ‰€æœ‰å…ƒç´ è¢«åŠ åˆ°ä¸€èµ·ï¼Œ
        # å¹¶ä»¥æ­¤è®¡ç®—å…³äº[`w`, `b`]çš„æ¢¯åº¦
        f.sum().backward()
        sgd([w, b], batch_size, lr)  # ä½¿ç”¨å‚æ•°çš„æ¢¯åº¦æ›´æ–°å‚æ•°
    with torch.no_grad():
        train_l = loss(net(features, w, b), labels)
        print("w {0} \nb {1} \nloss {2:f}".format(w, b, float(train_l.mean())))

print("wè¯¯å·® ", true_w - w, "\nbè¯¯å·® ", true_b - b)</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_çº¿æ€§å›å½’çš„ç®€æ´å®ç°"><a class="anchor" href="#_çº¿æ€§å›å½’çš„ç®€æ´å®ç°"></a>2.3. çº¿æ€§å›å½’çš„ç®€æ´å®ç°</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch
from torch.utils import data
from torch import nn
from d2l import torch as d2l

'''ç”Ÿæˆæ•°æ®é›†'''
true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = d2l.synthetic_data(true_w, true_b, 1000)

'''è¯»å–æ•°æ®é›†'''
def load_array(data_arrays, batch_size, is_train=True):  #@save
    """æ„é€ ä¸€ä¸ªPyTorchæ•°æ®è¿­ä»£å™¨"""
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)

batch_size = 10
data_iter = load_array((features, labels), batch_size)

'''å®šä¹‰æ¨¡å‹'''
net = nn.Sequential(nn.Linear(2, 1))
'''åˆå§‹åŒ–æ¨¡å‹å‚æ•°'''
net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)

'''å®šä¹‰æŸå¤±å‡½æ•°'''
loss = nn.MSELoss()

'''å®šä¹‰ä¼˜åŒ–ç®—æ³•'''
trainer = torch.optim.SGD(net.parameters(), lr=0.03)

'''è®­ç»ƒ'''
num_epochs = 3
for epoch in range(num_epochs):
    for X, y in data_iter:
        l = loss(net(X) ,y)
        trainer.zero_grad()
        l.backward()
        trainer.step()
    l = loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {l:f}')

w = net[0].weight.data
print('wçš„ä¼°è®¡è¯¯å·®ï¼š', true_w - w.reshape(true_w.shape))
b = net[0].bias.data
print('bçš„ä¼°è®¡è¯¯å·®ï¼š', true_b - b)</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_å›¾åƒåˆ†ç±»æ•°æ®é›†"><a class="anchor" href="#_å›¾åƒåˆ†ç±»æ•°æ®é›†"></a>2.4. å›¾åƒåˆ†ç±»æ•°æ®é›†</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch
import torchvision
from torch.utils import data
from torchvision import transforms
from d2l import torch as d2l

d2l.use_svg_display()

'''è¯»å–æ•°æ®é›†'''
# é€šè¿‡ToTensorå®ä¾‹å°†å›¾åƒæ•°æ®ä»PILç±»å‹å˜æ¢æˆ32ä½æµ®ç‚¹æ•°æ ¼å¼ï¼Œ
# å¹¶é™¤ä»¥255ä½¿å¾—æ‰€æœ‰åƒç´ çš„æ•°å€¼å‡åœ¨0åˆ°1ä¹‹é—´
trans = transforms.ToTensor()
mnist_train = torchvision.datasets.FashionMNIST(
    root="../data", train=True, transform=trans, download=True)
mnist_test = torchvision.datasets.FashionMNIST(
    root="../data", train=False, transform=trans, download=True)

def get_fashion_mnist_labels(labels):  #@save
    """è¿”å›Fashion-MNISTæ•°æ®é›†çš„æ–‡æœ¬æ ‡ç­¾"""
    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
    return [text_labels[int(i)] for i in labels]


'''å¯è§†åŒ–æ ·æœ¬'''
def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save
    """ç»˜åˆ¶å›¾åƒåˆ—è¡¨"""
    figsize = (num_cols * scale, num_rows * scale)
    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)
    axes = axes.flatten()
    for i, (ax, img) in enumerate(zip(axes, imgs)):
        if torch.is_tensor(img):
            # å›¾ç‰‡å¼ é‡
            ax.imshow(img.numpy())
        else:
            # PILå›¾ç‰‡
            ax.imshow(img)
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        if titles:
            ax.set_title(titles[i])
    return axes

X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))
show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));
d2l.plt.show()           #  <i class="conum" data-value="1"></i><b>(1)</b>

'''è¯»å–å°æ‰¹é‡'''
batch_size = 256

def get_dataloader_workers():  #@save
    """ä½¿ç”¨4ä¸ªè¿›ç¨‹æ¥è¯»å–æ•°æ®"""
    return 4

'''æ•´åˆæ‰€æœ‰ç»„ä»¶'''

def load_data_fashion_mnist(batch_size, resize=None):  #@save
    """ä¸‹è½½Fashion-MNISTæ•°æ®é›†ï¼Œç„¶åå°†å…¶åŠ è½½åˆ°å†…å­˜ä¸­"""
    trans = [transforms.ToTensor()]
    if resize:
        trans.insert(0, transforms.Resize(resize))
    trans = transforms.Compose(trans)
    mnist_train = torchvision.datasets.FashionMNIST(
        root="../data", train=True, transform=trans, download=True)
    mnist_test = torchvision.datasets.FashionMNIST(
        root="../data", train=False, transform=trans, download=True)
    return (data.DataLoader(mnist_train, batch_size, shuffle=True,
                            num_workers=get_dataloader_workers()),
            data.DataLoader(mnist_test, batch_size, shuffle=False,
                            num_workers=get_dataloader_workers()))</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>jupyter notebookä¸­ä¸éœ€è¦è¿™ä¸€è¡Œï¼Œpycharmä¸­éœ€è¦</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_softmaxå›å½’çš„ä»é›¶å¼€å§‹å®ç°"><a class="anchor" href="#_softmaxå›å½’çš„ä»é›¶å¼€å§‹å®ç°"></a>2.5. softmaxå›å½’çš„ä»é›¶å¼€å§‹å®ç°</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch
from IPython import display
from d2l import torch as d2l

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)

'''åˆå§‹åŒ–æ¨¡å‹å‚æ•°'''
num_inputs = 784
num_outputs = 10

W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)
b = torch.zeros(num_outputs, requires_grad=True)

'''å®šä¹‰softmaxæ“ä½œ'''
def softmax(X):
    X_exp = torch.exp(X)
    partition = X_exp.sum(1, keepdim=True)
    return X_exp / partition  # è¿™é‡Œåº”ç”¨äº†å¹¿æ’­æœºåˆ¶

'''å®šä¹‰æ¨¡å‹'''
def net(X):
    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)

'''å®šä¹‰æŸå¤±å‡½æ•°'''
def cross_entropy(y_hat, y):
    return - torch.log(y_hat[range(len(y_hat)), y])

'''åˆ†ç±»ç²¾åº¦'''
def accuracy(y_hat, y):  #@save
    """è®¡ç®—é¢„æµ‹æ­£ç¡®çš„æ•°é‡"""
    if len(y_hat.shape) &gt; 1 and y_hat.shape[1] &gt; 1:
        y_hat = y_hat.argmax(axis=1)
    cmp = y_hat.type(y.dtype) == y
    return float(cmp.type(y.dtype).sum())

def evaluate_accuracy(net, data_iter):  #@save
    """è®¡ç®—åœ¨æŒ‡å®šæ•°æ®é›†ä¸Šæ¨¡å‹çš„ç²¾åº¦"""
    if isinstance(net, torch.nn.Module):
        net.eval()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    metric = Accumulator(2)  # æ­£ç¡®é¢„æµ‹æ•°ã€é¢„æµ‹æ€»æ•°
    with torch.no_grad():
        for X, y in data_iter:
            metric.add(accuracy(net(X), y), y.numel())
    return metric[0] / metric[1]

class Accumulator:  #@save
    """åœ¨nä¸ªå˜é‡ä¸Šç´¯åŠ """
    def __init__(self, n):
        self.data = [0.0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]

'''è®­ç»ƒ'''
def train_epoch_ch3(net, train_iter, loss, updater):  #@save
    """è®­ç»ƒæ¨¡å‹ä¸€ä¸ªè¿­ä»£å‘¨æœŸï¼ˆå®šä¹‰è§ç¬¬3ç« ï¼‰"""
    # å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
    if isinstance(net, torch.nn.Module):
        net.train()
    # è®­ç»ƒæŸå¤±æ€»å’Œã€è®­ç»ƒå‡†ç¡®åº¦æ€»å’Œã€æ ·æœ¬æ•°
    metric = Accumulator(3)
    for X, y in train_iter:
        # è®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°å‚æ•°
        y_hat = net(X)
        l = loss(y_hat, y)
        if isinstance(updater, torch.optim.Optimizer):
            # ä½¿ç”¨PyTorchå†…ç½®çš„ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
            updater.zero_grad()
            l.mean().backward()
            updater.step()
        else:
            # ä½¿ç”¨å®šåˆ¶çš„ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
            l.sum().backward()
            updater(X.shape[0])
        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())
    # è¿”å›è®­ç»ƒæŸå¤±å’Œè®­ç»ƒç²¾åº¦
    return metric[0] / metric[2], metric[1] / metric[2]

class Animator:  #@save
    """åœ¨åŠ¨ç”»ä¸­ç»˜åˆ¶æ•°æ®"""
    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,
                 ylim=None, xscale='linear', yscale='linear',
                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,
                 figsize=(3.5, 2.5)):
        # å¢é‡åœ°ç»˜åˆ¶å¤šæ¡çº¿
        if legend is None:
            legend = []
        d2l.use_svg_display()
        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)
        if nrows * ncols == 1:
            self.axes = [self.axes, ]
        # ä½¿ç”¨lambdaå‡½æ•°æ•è·å‚æ•°
        self.config_axes = lambda: d2l.set_axes(
            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)
        self.X, self.Y, self.fmts = None, None, fmts

    def add(self, x, y):
        # å‘å›¾è¡¨ä¸­æ·»åŠ å¤šä¸ªæ•°æ®ç‚¹
        if not hasattr(y, "__len__"):
            y = [y]
        n = len(y)
        if not hasattr(x, "__len__"):
            x = [x] * n
        if not self.X:
            self.X = [[] for _ in range(n)]
        if not self.Y:
            self.Y = [[] for _ in range(n)]
        for i, (a, b) in enumerate(zip(x, y)):
            if a is not None and b is not None:
                self.X[i].append(a)
                self.Y[i].append(b)
        self.axes[0].cla()
        for x, y, fmt in zip(self.X, self.Y, self.fmts):
            self.axes[0].plot(x, y, fmt)
        self.config_axes()
        display.display(self.fig)
        display.clear_output(wait=True)

def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save
    """è®­ç»ƒæ¨¡å‹ï¼ˆå®šä¹‰è§ç¬¬3ç« ï¼‰"""
    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],
                        legend=['train loss', 'train acc', 'test acc'])
    for epoch in range(num_epochs):
        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)
        test_acc = evaluate_accuracy(net, test_iter)
        animator.add(epoch + 1, train_metrics + (test_acc,))
    train_loss, train_acc = train_metrics
    assert train_loss &lt; 0.5, train_loss
    assert train_acc &lt;= 1 and train_acc &gt; 0.7, train_acc
    assert test_acc &lt;= 1 and test_acc &gt; 0.7, test_acc

lr = 0.1

def updater(batch_size):
    return d2l.sgd([W, b], lr, batch_size)

num_epochs = 10
train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)

'''é¢„æµ‹'''
def predict_ch3(net, test_iter, n=6):  #@save
    """é¢„æµ‹æ ‡ç­¾ï¼ˆå®šä¹‰è§ç¬¬3ç« ï¼‰"""
    for X, y in test_iter:
        break
    trues = d2l.get_fashion_mnist_labels(y)
    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))
    titles = [true +'\n' + pred for true, pred in zip(trues, preds)]
    d2l.show_images(
        X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])

predict_ch3(net, test_iter)</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_softmaxå›å½’çš„ç®€æ´å®ç°"><a class="anchor" href="#_softmaxå›å½’çš„ç®€æ´å®ç°"></a>2.6. softmaxå›å½’çš„ç®€æ´å®ç°</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch
from torch import nn
from d2l import torch as d2l

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)

# PyTorchä¸ä¼šéšå¼åœ°è°ƒæ•´è¾“å…¥çš„å½¢çŠ¶ã€‚å› æ­¤ï¼Œ
# æˆ‘ä»¬åœ¨çº¿æ€§å±‚å‰å®šä¹‰äº†å±•å¹³å±‚ï¼ˆflattenï¼‰ï¼Œæ¥è°ƒæ•´ç½‘ç»œè¾“å…¥çš„å½¢çŠ¶
net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

net.apply(init_weights)

loss = nn.CrossEntropyLoss(reduction='none')

trainer = torch.optim.SGD(net.parameters(), lr=0.1)

'''è®­ç»ƒ'''
num_epochs = 10
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2025-01-02 11:56:50 UTC
</div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/highlight.min.js"></script>
<script>
if (!hljs.initHighlighting.called) {
  hljs.initHighlighting.called = true
  ;[].slice.call(document.querySelectorAll('pre.highlight > code')).forEach(function (el) { hljs.highlightBlock(el) })
}
</script>
<script src="https://utteranc.es/client.js"
        repo="pxzxj/articles"
        issue-term="title"
        label="utteranc"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
</div>
  </div>
</div>
</body>
</html>